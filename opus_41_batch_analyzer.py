#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OPUS 4.1 BATCH ANALYZER
An√°lise espec√≠fica de por que uploads em batch falham parcialmente
"""

import streamlit as st
import pandas as pd
import json
import time
from datetime import datetime
import requests
import traceback

class Opus41BatchAnalyzer:
    """An√°lise especializada para uploads em batch que falham parcialmente"""
    
    def __init__(self):
        self.analysis_results = {
            "batch_scenarios": [],
            "rate_limit_tests": [],
            "memory_snapshots": [],
            "network_patterns": [],
            "firebase_responses": [],
            "failure_distribution": {}
        }
    
    def main(self):
        st.set_page_config(
            page_title="OPUS 4.1 Batch Analyzer",
            page_icon="üìä",
            layout="wide"
        )
        
        st.title("üìä OPUS 4.1 BATCH ANALYZER")
        st.markdown("---")
        
        st.error("üî¨ FOCO: Por que 198 ingredientes ‚Üí apenas parcialmente salvos?")
        
        if 'user' not in st.session_state:
            st.error("‚ùå Login necess√°rio")
            return
        
        # An√°lises espec√≠ficas para batch
        self.analyze_current_state()
        self.test_batch_scenarios() 
        self.analyze_rate_limiting()
        self.test_memory_constraints()
        self.analyze_network_patterns()
        self.generate_batch_strategy()
    
    def analyze_current_state(self):
        """An√°lise do estado atual para entender o que foi salvo vs n√£o salvo"""
        st.header("üìä 1. AN√ÅLISE DO ESTADO ATUAL")
        
        try:
            from utils.database import get_database_manager
            
            db_manager = get_database_manager()
            user_id = st.session_state.user['uid']
            
            current_df = db_manager.get_user_ingredients(user_id)
            
            state_analysis = {
                "current_count": len(current_df),
                "expected_count": 198,
                "missing_count": 198 - len(current_df),
                "success_rate": (len(current_df) / 198) * 100 if len(current_df) > 0 else 0,
                "analysis_timestamp": datetime.now().isoformat()
            }
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Salvos Atualmente", state_analysis["current_count"])
                
            with col2:
                st.metric("Faltando", state_analysis["missing_count"])
                
            with col3:
                st.metric("Taxa de Sucesso", f"{state_analysis['success_rate']:.1f}%")
            
            # An√°lise de distribui√ß√£o se h√° dados
            if not current_df.empty:
                st.subheader("üìà DISTRIBUI√á√ÉO DOS DADOS SALVOS")
                
                # Por categoria se dispon√≠vel
                if 'Categoria' in current_df.columns:
                    category_dist = current_df['Categoria'].value_counts()
                    st.bar_chart(category_dist)
                    
                    # Identificar categorias que podem ter sido mais afetadas
                    st.subheader("üéØ PADR√ïES IDENTIFICADOS")
                    
                    total_categories = len(category_dist)
                    avg_per_category = len(current_df) / total_categories if total_categories > 0 else 0
                    
                    underrepresented = category_dist[category_dist < avg_per_category * 0.5]
                    
                    if not underrepresented.empty:
                        st.warning("‚ö†Ô∏è CATEGORIAS SUB-REPRESENTADAS (poss√≠vel padr√£o de falha):")
                        for cat, count in underrepresented.items():
                            st.error(f"‚ùå {cat}: apenas {count} ingredientes")
                    
                # An√°lise temporal se h√° timestamps
                if 'created_at' in current_df.columns:
                    st.subheader("‚è∞ AN√ÅLISE TEMPORAL")
                    
                    try:
                        current_df['created_at_parsed'] = pd.to_datetime(current_df['created_at'])
                        
                        # Agrupar por minuto para ver quando parou
                        by_minute = current_df.groupby(current_df['created_at_parsed'].dt.floor('T')).size()
                        
                        st.line_chart(by_minute)
                        st.caption("Uploads por minuto - queda indica onde o upload parou")
                        
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è Erro na an√°lise temporal: {e}")
                
                # Amostra dos dados salvos
                with st.expander("üìã Amostra dos Ingredientes Salvos", expanded=False):
                    st.dataframe(current_df.head(10))
            
            else:
                st.error("‚ùå NENHUM ingrediente encontrado no Firebase!")
                st.error("üö® FALHA TOTAL do upload - problema mais grave")
            
            self.analysis_results["current_state"] = state_analysis
            
        except Exception as e:
            st.error(f"‚ùå Erro na an√°lise de estado: {e}")
            st.code(traceback.format_exc())
    
    def test_batch_scenarios(self):
        """Testa diferentes cen√°rios de batch para identificar falhas"""
        st.header("üß™ 2. TESTE DE CEN√ÅRIOS DE BATCH")
        
        scenarios = [
            {"name": "Micro Batch", "size": 5, "delay": 0.1},
            {"name": "Small Batch", "size": 10, "delay": 0.5}, 
            {"name": "Medium Batch", "size": 25, "delay": 1.0},
            {"name": "Large Batch", "size": 50, "delay": 2.0}
        ]
        
        st.info("üéØ Objetivo: Encontrar tamanho de batch que n√£o falha")
        
        if st.button("üöÄ EXECUTAR TESTES DE BATCH", type="primary"):
            self._run_batch_scenarios(scenarios)
    
    def _run_batch_scenarios(self, scenarios):
        """Executa testes de diferentes tamanhos de batch"""
        try:
            from utils.firestore_client import get_firestore_client
            
            client = get_firestore_client()
            if not client:
                st.error("‚ùå Cliente Firebase n√£o dispon√≠vel")
                return
            
            user_id = st.session_state.user['uid']
            collection_path = f"users/{user_id}/test_batches"
            
            st.subheader("üìä RESULTADOS DOS TESTES")
            
            for scenario in scenarios:
                st.write(f"üß™ **Testando: {scenario['name']}** ({scenario['size']} items, {scenario['delay']}s delay)")
                
                batch_result = {
                    "scenario": scenario,
                    "start_time": time.time(),
                    "attempts": [],
                    "success_count": 0,
                    "failure_count": 0
                }
                
                # Criar dados de teste para este batch
                test_items = []
                for i in range(scenario['size']):
                    test_item = {
                        "nome": f"BatchTest_{scenario['name']}_{i}",
                        "categoria": f"TestCat_{i % 3}",  # 3 categorias diferentes
                        "preco": 10.0 + (i * 0.5),
                        "ativo": True,
                        "test_batch": scenario['name'],
                        "test_timestamp": datetime.now().isoformat(),
                        "user_id": user_id
                    }
                    test_items.append(test_item)
                
                # Progress para este cen√°rio
                progress = st.progress(0)
                status = st.empty()
                
                # Executar batch
                for i, item in enumerate(test_items):
                    try:
                        status.info(f"üì¶ {scenario['name']}: {i+1}/{scenario['size']} - {item['nome']}")
                        
                        item_start = time.time()
                        result = client.collection(collection_path).add(item)
                        item_duration = time.time() - item_start
                        
                        if result:
                            batch_result["success_count"] += 1
                            attempt_log = {
                                "item_index": i,
                                "status": "SUCCESS",
                                "duration": item_duration,
                                "timestamp": datetime.now().isoformat()
                            }
                        else:
                            batch_result["failure_count"] += 1
                            attempt_log = {
                                "item_index": i,
                                "status": "NO_RESULT",
                                "duration": item_duration,
                                "timestamp": datetime.now().isoformat()
                            }
                        
                        batch_result["attempts"].append(attempt_log)
                        
                        # Update progress
                        progress.progress((i + 1) / scenario['size'])
                        
                        # Delay entre items
                        time.sleep(scenario['delay'])
                    
                    except Exception as item_error:
                        batch_result["failure_count"] += 1
                        attempt_log = {
                            "item_index": i,
                            "status": "EXCEPTION",
                            "error": str(item_error),
                            "timestamp": datetime.now().isoformat()
                        }
                        batch_result["attempts"].append(attempt_log)
                
                batch_result["end_time"] = time.time()
                batch_result["total_duration"] = batch_result["end_time"] - batch_result["start_time"]
                batch_result["success_rate"] = (batch_result["success_count"] / scenario['size']) * 100
                
                self.analysis_results["batch_scenarios"].append(batch_result)
                
                # Mostrar resultado deste cen√°rio
                if batch_result["success_rate"] == 100:
                    st.success(f"‚úÖ {scenario['name']}: {batch_result['success_rate']:.1f}% sucesso em {batch_result['total_duration']:.1f}s")
                elif batch_result["success_rate"] > 80:
                    st.warning(f"‚ö†Ô∏è {scenario['name']}: {batch_result['success_rate']:.1f}% sucesso em {batch_result['total_duration']:.1f}s")
                else:
                    st.error(f"‚ùå {scenario['name']}: {batch_result['success_rate']:.1f}% sucesso em {batch_result['total_duration']:.1f}s")
                
                # Delay entre cen√°rios
                time.sleep(2)
            
            # An√°lise comparativa
            st.subheader("üìä AN√ÅLISE COMPARATIVA")
            
            scenario_comparison = []
            for result in self.analysis_results["batch_scenarios"]:
                scenario_comparison.append({
                    "Cen√°rio": result["scenario"]["name"],
                    "Tamanho": result["scenario"]["size"],
                    "Taxa Sucesso": f"{result['success_rate']:.1f}%",
                    "Dura√ß√£o Total": f"{result['total_duration']:.1f}s",
                    "Tempo/Item": f"{result['total_duration']/result['scenario']['size']:.2f}s"
                })
            
            comparison_df = pd.DataFrame(scenario_comparison)
            st.dataframe(comparison_df)
            
            # Identificar melhor cen√°rio
            best_scenario = max(self.analysis_results["batch_scenarios"], key=lambda x: x["success_rate"])
            
            if best_scenario["success_rate"] == 100:
                st.success(f"üéâ **CEN√ÅRIO IDEAL ENCONTRADO**: {best_scenario['scenario']['name']}")
                st.success(f"‚úÖ Tamanho: {best_scenario['scenario']['size']} items")
                st.success(f"‚úÖ Delay: {best_scenario['scenario']['delay']}s")
                st.success(f"‚úÖ 100% sucesso em {best_scenario['total_duration']:.1f}s")
            else:
                st.warning(f"‚ö†Ô∏è **MELHOR CEN√ÅRIO**: {best_scenario['scenario']['name']} ({best_scenario['success_rate']:.1f}% sucesso)")
                st.warning("üö® Nenhum cen√°rio atingiu 100% - problema sist√™mico mais profundo")
            
        except Exception as e:
            st.error(f"üö® Erro nos testes de batch: {e}")
            st.code(traceback.format_exc())
    
    def analyze_rate_limiting(self):
        """An√°lise espec√≠fica de rate limiting do Firebase"""
        st.header("‚è±Ô∏è 3. AN√ÅLISE DE RATE LIMITING")
        
        st.info("üéØ Objetivo: Detectar se Firebase est√° limitando opera√ß√µes por segundo")
        
        if st.button("üîç TESTAR RATE LIMITING"):
            self._test_rate_limiting()
    
    def _test_rate_limiting(self):
        """Testa limites de rate do Firebase"""
        try:
            from utils.firestore_client import get_firestore_client
            
            client = get_firestore_client()
            if not client:
                st.error("‚ùå Cliente n√£o dispon√≠vel")
                return
            
            user_id = st.session_state.user['uid']
            collection_path = f"users/{user_id}/rate_limit_test"
            
            # Teste de velocidades diferentes
            rate_tests = [
                {"name": "Ultra R√°pido", "delay": 0.01, "count": 20},
                {"name": "Muito R√°pido", "delay": 0.1, "count": 20},
                {"name": "R√°pido", "delay": 0.5, "count": 20},
                {"name": "Normal", "delay": 1.0, "count": 20}
            ]
            
            st.subheader("üîÑ TESTANDO DIFERENTES VELOCIDADES")
            
            for test in rate_tests:
                st.write(f"‚ö° **{test['name']}**: {test['count']} items com {test['delay']}s delay")
                
                rate_result = {
                    "test_config": test,
                    "start_time": time.time(),
                    "success_count": 0,
                    "failure_count": 0,
                    "response_times": [],
                    "errors": []
                }
                
                progress = st.progress(0)
                
                for i in range(test['count']):
                    try:
                        test_data = {
                            "nome": f"RateTest_{test['name']}_{i}",
                            "test_type": "rate_limit",
                            "delay_used": test['delay'],
                            "sequence": i,
                            "timestamp": datetime.now().isoformat(),
                            "user_id": user_id
                        }
                        
                        item_start = time.time()
                        result = client.collection(collection_path).add(test_data)
                        item_end = time.time()
                        
                        response_time = item_end - item_start
                        rate_result["response_times"].append(response_time)
                        
                        if result:
                            rate_result["success_count"] += 1
                        else:
                            rate_result["failure_count"] += 1
                            rate_result["errors"].append(f"Item {i}: No result")
                        
                        progress.progress((i + 1) / test['count'])
                        
                        # Delay configurado
                        time.sleep(test['delay'])
                    
                    except Exception as e:
                        rate_result["failure_count"] += 1
                        rate_result["errors"].append(f"Item {i}: {str(e)}")
                
                rate_result["end_time"] = time.time()
                rate_result["total_duration"] = rate_result["end_time"] - rate_result["start_time"]
                rate_result["success_rate"] = (rate_result["success_count"] / test['count']) * 100
                rate_result["avg_response_time"] = sum(rate_result["response_times"]) / len(rate_result["response_times"]) if rate_result["response_times"] else 0
                
                self.analysis_results["rate_limit_tests"].append(rate_result)
                
                # Mostrar resultado
                if rate_result["success_rate"] == 100:
                    st.success(f"‚úÖ {test['name']}: 100% sucesso, {rate_result['avg_response_time']:.2f}s resp m√©dio")
                else:
                    st.error(f"‚ùå {test['name']}: {rate_result['success_rate']:.1f}% sucesso, {len(rate_result['errors'])} erros")
                    
                    if rate_result['errors']:
                        with st.expander(f"‚ùå Erros {test['name']}", expanded=False):
                            for error in rate_result['errors'][:5]:  # Primeiros 5
                                st.error(error)
            
            # An√°lise dos resultados de rate limiting
            st.subheader("üìä AN√ÅLISE DE RATE LIMITING")
            
            rate_comparison = []
            for result in self.analysis_results["rate_limit_tests"]:
                rate_comparison.append({
                    "Velocidade": result["test_config"]["name"],
                    "Delay": f"{result['test_config']['delay']}s",
                    "Taxa Sucesso": f"{result['success_rate']:.1f}%",
                    "Resp M√©dio": f"{result['avg_response_time']:.3f}s",
                    "Total": f"{result['total_duration']:.1f}s"
                })
            
            rate_df = pd.DataFrame(rate_comparison)
            st.dataframe(rate_df)
            
            # Identificar ponto de quebra
            successful_tests = [r for r in self.analysis_results["rate_limit_tests"] if r["success_rate"] == 100]
            
            if successful_tests:
                fastest_successful = min(successful_tests, key=lambda x: x["test_config"]["delay"])
                st.success(f"üéØ **VELOCIDADE M√ÅXIMA SEM FALHA**: {fastest_successful['test_config']['name']}")
                st.success(f"‚úÖ Delay seguro: {fastest_successful['test_config']['delay']}s entre uploads")
            else:
                st.error("üö® **TODOS OS TESTES FALHARAM** - problema n√£o √© rate limiting")
                st.error("üö® Investigar outras causas: rede, autentica√ß√£o, dados")
        
        except Exception as e:
            st.error(f"üö® Erro no teste de rate limiting: {e}")
    
    def test_memory_constraints(self):
        """Testa se problema √© de mem√≥ria/recursos"""
        st.header("üíæ 4. AN√ÅLISE DE MEM√ìRIA E RECURSOS")
        
        try:
            import psutil
            import gc
            
            # Estado inicial da mem√≥ria
            process = psutil.Process()
            initial_memory = process.memory_info()
            
            memory_analysis = {
                "initial_memory_mb": initial_memory.rss / 1024 / 1024,
                "initial_memory_percent": process.memory_percent(),
                "cpu_percent": process.cpu_percent(interval=1)
            }
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Mem√≥ria Atual", f"{memory_analysis['initial_memory_mb']:.1f} MB")
            
            with col2:
                st.metric("% Mem√≥ria Sistema", f"{memory_analysis['initial_memory_percent']:.1f}%")
            
            with col3:
                st.metric("CPU %", f"{memory_analysis['cpu_percent']:.1f}%")
            
            # Teste de carga de mem√≥ria
            if st.button("üß™ TESTAR IMPACTO MEM√ìRIA"):
                
                st.info("üîÑ Simulando carga de 198 ingredientes...")
                
                # Simular carregamento de 198 ingredientes
                large_dataset = []
                for i in range(198):
                    ingredient = {
                        "nome": f"Ingrediente_{i:03d}",
                        "categoria": f"Categoria_{i % 10}",
                        "preco": 10.0 + (i * 0.1),
                        "ativo": True,
                        "observacoes": "Teste de mem√≥ria " * 20,  # String longa
                        "dados_extras": list(range(100))  # Lista para ocupar mem√≥ria
                    }
                    large_dataset.append(ingredient)
                
                # Medir mem√≥ria ap√≥s carregamento
                after_load_memory = process.memory_info()
                memory_increase = (after_load_memory.rss - initial_memory.rss) / 1024 / 1024
                
                st.info(f"üìä Aumento de mem√≥ria: {memory_increase:.1f} MB para 198 ingredientes")
                
                if memory_increase > 100:  # Mais de 100MB
                    st.warning("‚ö†Ô∏è Alto uso de mem√≥ria detectado")
                else:
                    st.success("‚úÖ Uso de mem√≥ria normal")
                
                # Limpar dados de teste
                del large_dataset
                gc.collect()
                
                memory_analysis["memory_test"] = {
                    "memory_increase_mb": memory_increase,
                    "high_memory_usage": memory_increase > 100
                }
            
            # Teste de garbage collection
            if st.button("üóëÔ∏è TESTAR GARBAGE COLLECTION"):
                st.info("üîÑ Executando garbage collection...")
                
                before_gc = process.memory_info().rss / 1024 / 1024
                
                # For√ßar garbage collection
                collected = gc.collect()
                
                after_gc = process.memory_info().rss / 1024 / 1024
                memory_freed = before_gc - after_gc
                
                st.info(f"üóëÔ∏è Objetos coletados: {collected}")
                st.info(f"üíæ Mem√≥ria liberada: {memory_freed:.1f} MB")
                
                memory_analysis["gc_test"] = {
                    "objects_collected": collected,
                    "memory_freed_mb": memory_freed
                }
            
            self.analysis_results["memory_analysis"] = memory_analysis
        
        except ImportError:
            st.warning("‚ö†Ô∏è psutil n√£o dispon√≠vel - an√°lise de mem√≥ria limitada")
        except Exception as e:
            st.error(f"‚ùå Erro na an√°lise de mem√≥ria: {e}")
    
    def analyze_network_patterns(self):
        """Analisa padr√µes de rede que podem causar falhas"""
        st.header("üåê 5. AN√ÅLISE DE PADR√ïES DE REDE")
        
        if st.button("üîç TESTAR CONECTIVIDADE FIREBASE"):
            self._test_firebase_connectivity()
    
    def _test_firebase_connectivity(self):
        """Testa conectividade e lat√™ncia com Firebase"""
        try:
            # Testar diferentes endpoints Firebase
            endpoints = [
                {"name": "Identity Toolkit", "url": "https://identitytoolkit.googleapis.com/v1/accounts:lookup"},
                {"name": "Firestore REST", "url": "https://firestore.googleapis.com/v1/projects/marmita-fit-6a3ca/databases/(default)/documents"},
                {"name": "Secure Token", "url": "https://securetoken.googleapis.com/v1/token"}
            ]
            
            st.subheader("üì° TESTE DE CONECTIVIDADE")
            
            connectivity_results = []
            
            for endpoint in endpoints:
                try:
                    st.info(f"üîÑ Testando: {endpoint['name']}")
                    
                    # Teste de lat√™ncia
                    start_time = time.time()
                    
                    # GET request simples para testar conectividade
                    response = requests.get(endpoint['url'], timeout=5)
                    
                    end_time = time.time()
                    latency = (end_time - start_time) * 1000  # ms
                    
                    result = {
                        "endpoint": endpoint['name'],
                        "status_code": response.status_code,
                        "latency_ms": latency,
                        "accessible": True,
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    if latency < 500:  # Menos de 500ms
                        st.success(f"‚úÖ {endpoint['name']}: {response.status_code} ({latency:.0f}ms)")
                    else:
                        st.warning(f"‚ö†Ô∏è {endpoint['name']}: {response.status_code} ({latency:.0f}ms) - Lat√™ncia alta")
                    
                except requests.exceptions.Timeout:
                    result = {
                        "endpoint": endpoint['name'],
                        "error": "TIMEOUT",
                        "latency_ms": 5000,  # 5s timeout
                        "accessible": False
                    }
                    st.error(f"‚ùå {endpoint['name']}: TIMEOUT (>5s)")
                
                except requests.exceptions.RequestException as e:
                    result = {
                        "endpoint": endpoint['name'],
                        "error": str(e),
                        "accessible": False
                    }
                    st.error(f"‚ùå {endpoint['name']}: {str(e)}")
                
                connectivity_results.append(result)
            
            # An√°lise de conectividade
            accessible_count = sum(1 for r in connectivity_results if r.get('accessible', False))
            avg_latency = sum(r.get('latency_ms', 0) for r in connectivity_results if 'latency_ms' in r) / len(connectivity_results)
            
            st.subheader("üìä RESUMO DE CONECTIVIDADE")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Endpoints Acess√≠veis", f"{accessible_count}/{len(endpoints)}")
            
            with col2:
                st.metric("Lat√™ncia M√©dia", f"{avg_latency:.0f}ms")
            
            if accessible_count < len(endpoints):
                st.error("üö® PROBLEMAS DE CONECTIVIDADE detectados")
                st.error("Causa prov√°vel: Rede, firewall ou proxy bloqueando Firebase")
            elif avg_latency > 1000:
                st.warning("‚ö†Ô∏è LAT√äNCIA ALTA detectada")
                st.warning("Uploads podem falhar por timeout")
            else:
                st.success("‚úÖ CONECTIVIDADE OK - problema n√£o √© de rede")
            
            self.analysis_results["connectivity_test"] = connectivity_results
        
        except Exception as e:
            st.error(f"üö® Erro no teste de conectividade: {e}")
    
    def generate_batch_strategy(self):
        """Gera estrat√©gia de batch baseada nas an√°lises"""
        st.header("üéØ 6. ESTRAT√âGIA DE BATCH RECOMENDADA")
        
        # Compilar an√°lises para gerar recomenda√ß√£o
        recommendations = {
            "recommended_batch_size": 25,
            "recommended_delay": 1.0,
            "confidence_level": "BAIXA",
            "reasoning": [],
            "alternative_strategies": []
        }
        
        # An√°lise baseada nos testes de batch
        if "batch_scenarios" in self.analysis_results and self.analysis_results["batch_scenarios"]:
            successful_scenarios = [s for s in self.analysis_results["batch_scenarios"] if s["success_rate"] == 100]
            
            if successful_scenarios:
                # Pegar o maior batch size que deu 100% sucesso
                best_scenario = max(successful_scenarios, key=lambda x: x["scenario"]["size"])
                
                recommendations["recommended_batch_size"] = best_scenario["scenario"]["size"]
                recommendations["recommended_delay"] = best_scenario["scenario"]["delay"] 
                recommendations["confidence_level"] = "ALTA"
                recommendations["reasoning"].append(f"Teste mostrou 100% sucesso com {best_scenario['scenario']['size']} items")
            else:
                # Nenhum cen√°rio deu 100%, pegar o melhor
                if self.analysis_results["batch_scenarios"]:
                    best_scenario = max(self.analysis_results["batch_scenarios"], key=lambda x: x["success_rate"])
                    
                    recommendations["recommended_batch_size"] = best_scenario["scenario"]["size"]
                    recommendations["recommended_delay"] = best_scenario["scenario"]["delay"] * 2  # Dobrar delay
                    recommendations["confidence_level"] = "M√âDIA"
                    recommendations["reasoning"].append(f"Melhor cen√°rio: {best_scenario['success_rate']:.1f}% sucesso")
        
        # An√°lise baseada no rate limiting
        if "rate_limit_tests" in self.analysis_results and self.analysis_results["rate_limit_tests"]:
            successful_rates = [r for r in self.analysis_results["rate_limit_tests"] if r["success_rate"] == 100]
            
            if successful_rates:
                fastest_safe = min(successful_rates, key=lambda x: x["test_config"]["delay"])
                
                if fastest_safe["test_config"]["delay"] < recommendations["recommended_delay"]:
                    recommendations["recommended_delay"] = fastest_safe["test_config"]["delay"]
                    recommendations["reasoning"].append(f"Rate limit OK com {fastest_safe['test_config']['delay']}s delay")
            else:
                # Rate limiting detectado - aumentar delay
                recommendations["recommended_delay"] = max(2.0, recommendations["recommended_delay"])
                recommendations["reasoning"].append("Rate limiting detectado - delay aumentado")
        
        # An√°lise de mem√≥ria
        if "memory_analysis" in self.analysis_results:
            memory = self.analysis_results["memory_analysis"]
            
            if memory.get("memory_test", {}).get("high_memory_usage", False):
                recommendations["recommended_batch_size"] = min(10, recommendations["recommended_batch_size"])
                recommendations["reasoning"].append("Alto uso de mem√≥ria - batch reduzido")
        
        # An√°lise de conectividade
        if "connectivity_test" in self.analysis_results:
            connectivity = self.analysis_results["connectivity_test"]
            accessible = sum(1 for r in connectivity in r.get('accessible', False))
            
            if accessible < len(connectivity):
                recommendations["recommended_delay"] = max(3.0, recommendations["recommended_delay"])
                recommendations["reasoning"].append("Problemas de conectividade - delay aumentado")
        
        # Estrat√©gias alternativas
        current_state = self.analysis_results.get("current_state", {})
        missing_count = current_state.get("missing_count", 0)
        
        if missing_count > 150:
            recommendations["alternative_strategies"].append({
                "strategy": "UPLOAD INCREMENTAL",
                "description": "Fazer upload apenas dos ingredientes faltantes",
                "batch_size": 5,
                "delay": 2.0
            })
        
        if missing_count > 100:
            recommendations["alternative_strategies"].append({
                "strategy": "MANUAL CHUNKING", 
                "description": "Dividir 198 ingredientes em 4 grupos de ~50",
                "batch_size": 15,
                "delay": 1.5
            })
        
        recommendations["alternative_strategies"].append({
            "strategy": "ULTRA CONSERVADOR",
            "description": "M√°xima garantia de sucesso",
            "batch_size": 1,
            "delay": 3.0
        })
        
        # Apresentar recomenda√ß√µes
        st.subheader(f"üéØ ESTRAT√âGIA RECOMENDADA ({recommendations['confidence_level']} confian√ßa)")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("Batch Size", recommendations['recommended_batch_size'])
            
        with col2:
            st.metric("Delay entre Batches", f"{recommendations['recommended_delay']}s")
        
        st.subheader("üí° RACIOC√çNIO")
        for reason in recommendations["reasoning"]:
            st.info(f"‚úÖ {reason}")
        
        if not recommendations["reasoning"]:
            st.warning("‚ö†Ô∏è An√°lises insuficientes - usando defaults conservadores")
        
        # Estrat√©gias alternativas
        if recommendations["alternative_strategies"]:
            st.subheader("üîÑ ESTRAT√âGIAS ALTERNATIVAS")
            
            for i, strategy in enumerate(recommendations["alternative_strategies"]):
                with st.expander(f"üìã {strategy['strategy']}", expanded=False):
                    st.info(strategy["description"])
                    st.info(f"Batch: {strategy['batch_size']}, Delay: {strategy['delay']}s")
        
        # C√≥digo para implementar
        st.subheader("üöÄ PR√ìXIMOS PASSOS")
        
        st.info("1. **Execute batch_upload_optimizer.py** com as configura√ß√µes recomendadas:")
        st.code(f"""
Configura√ß√µes:
- Batch Size: {recommendations['recommended_batch_size']}
- Delay entre lotes: {recommendations['recommended_delay']}s  
- Delay entre items: {recommendations['recommended_delay'] * 0.1}s
""")
        
        st.info("2. **Monitore** a taxa de sucesso durante o upload")
        st.info("3. **Se falhar**, tente estrat√©gia ULTRA CONSERVADOR")
        st.info("4. **Se continuar falhando**, problema √© arquitetural mais profundo")
        
        # Salvar recomenda√ß√µes
        self.analysis_results["recommendations"] = recommendations

def main():
    analyzer = Opus41BatchAnalyzer()
    analyzer.main()

if __name__ == "__main__":
    main()